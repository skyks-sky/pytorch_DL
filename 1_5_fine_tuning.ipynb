{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "1-5_fine_tuning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "0I-sJHPa4P_R"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyks-sky/pytorch_DL/blob/main/1_5_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I-sJHPa4P_R"
      },
      "source": [
        "# 1.5 「ファインチューニング」で精度向上を実現する方法\n",
        "\n",
        "- 本ファイルでは、学習済みのVGGモデルを使用し、ファインチューニングでアリとハチの画像を分類するモデルを学習します\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4usbRON4P_S"
      },
      "source": [
        "# 学習目標\n",
        "\n",
        "1.\tPyTorchでGPUを使用する実装コードを書けるようになる\n",
        "2.\t最適化手法の設定において、層ごとに異なる学習率を設定したファインチューニングを実装できるようになる\n",
        "3.\t学習したネットワークを保存・ロードできるようになる\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0hs48yG4Z9t"
      },
      "source": [
        "!git clone https://github.com/YutaroOgawa/pytorch_advanced.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc0ARzLg4aH9"
      },
      "source": [
        "%cd \"pytorch_advanced\"\n",
        "%cd \"1_image_classification\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnbAVu2s4aKL"
      },
      "source": [
        "# make_folders_and_data_downloads.ipynbの中身を実行\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "\n",
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "save_path = os.path.join(data_dir, \"imagenet_class_index.json\")\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
        "save_path = os.path.join(data_dir, \"hymenoptera_data.zip\")\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "    # ZIPファイルを読み込み\n",
        "    zip = zipfile.ZipFile(save_path)\n",
        "    zip.extractall(data_dir)  # ZIPを解凍\n",
        "    zip.close()  # ZIPファイルをクローズ\n",
        "\n",
        "    # ZIPファイルを消去\n",
        "    os.remove(save_path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J14EcTcS4aMB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EJGSp4j4aNv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD13WjfK4P_T"
      },
      "source": [
        "# 事前準備\n",
        "\n",
        "- 1.4節で解説したAWS EC2 のGPUインスタンスを使用します\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GvtJgNo4P_U"
      },
      "source": [
        "# パッケージのimport\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import models\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPyuMYYT4P_U"
      },
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TiMwlZG4P_V"
      },
      "source": [
        "# DatasetとDataLoaderを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPQNj0674P_V"
      },
      "source": [
        "# 1.3節で作成したクラスを同じフォルダにあるmake_dataset_dataloader.pyに記載して使用\n",
        "from utils.dataloader_image_classification import ImageTransform, make_datapath_list, HymenopteraDataset\n",
        "\n",
        "# アリとハチの画像へのファイルパスのリストを作成する\n",
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "# Datasetを作成する\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "train_dataset = HymenopteraDataset(\n",
        "    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
        "\n",
        "val_dataset = HymenopteraDataset(\n",
        "    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')\n",
        "\n",
        "\n",
        "# DataLoaderを作成する\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書オブジェクトにまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxeNzbcg4P_W"
      },
      "source": [
        "# ネットワークモデルの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruu-hhLf4P_W"
      },
      "source": [
        "# 学習済みのVGG-16モデルをロード\n",
        "\n",
        "# VGG-16モデルのインスタンスを生成\n",
        "use_pretrained = True  # 学習済みのパラメータを使用\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "# VGG16の最後の出力層の出力ユニットをアリとハチの2つに付け替える\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "# 訓練モードに設定\n",
        "net.train()\n",
        "\n",
        "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjK5Wi9r4P_W"
      },
      "source": [
        "# 損失関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP-yxph_4P_X"
      },
      "source": [
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgdWrOo04P_X"
      },
      "source": [
        "# 最適化手法を設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAh3NsEI4P_X"
      },
      "source": [
        "# ファインチューニングで学習させるパラメータを、変数params_to_updateの1～3に格納する\n",
        "\n",
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "# 学習させる層のパラメータ名を指定\n",
        "update_param_names_1 = [\"features\"]\n",
        "update_param_names_2 = [\"classifier.0.weight\",\n",
        "                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# パラメータごとに各リストに格納する\n",
        "for name, param in net.named_parameters():\n",
        "    if update_param_names_1[0] in name:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_1.append(param)\n",
        "        print(\"params_to_update_1に格納：\", name)\n",
        "\n",
        "    elif name in update_param_names_2:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_2.append(param)\n",
        "        print(\"params_to_update_2に格納：\", name)\n",
        "\n",
        "    elif name in update_param_names_3:\n",
        "        param.requires_grad = True\n",
        "        params_to_update_3.append(param)\n",
        "        print(\"params_to_update_3に格納：\", name)\n",
        "\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "        print(\"勾配計算なし。学習しない：\", name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88C42fbynEBL"
      },
      "source": [
        "#実際の重みパラメータが格納されている。\n",
        "print(params_to_update_1)\n",
        "print(params_to_update_2)\n",
        "print(params_to_update_3)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SK6VRKU4P_Y"
      },
      "source": [
        "# 最適化手法の設定\n",
        "\"\"\"\n",
        "SGD:確率的勾配降下法\n",
        "局所解に陥らないようにランダム性を追加した勾配降下法\n",
        "SGDの欠点は1つのでーたによる勾配で更新しないと次のデータに移れない点である。\n",
        "これでは並列化ができないという欠点がある。\n",
        "また、SGDでは1度の更新における更新量が大きいことによるオーバーシュートが発生して、ポテンシャルのくぼみにおける振動を起こしてしまう問題がある。\n",
        "そこで、更新量が大きいことによる振動を抑えるためにモーメンタムが考案された。\n",
        "モーメンタムはシンプルにシンプルに完成のイメージで、外力の効果をどれくらい自身に取り込むかを設定する方法である。\n",
        "\n",
        "\"\"\"\n",
        "optimizer = optim.SGD([\n",
        "    {'params': params_to_update_1, 'lr': 1e-4},\n",
        "    {'params': params_to_update_2, 'lr': 5e-4},\n",
        "    {'params': params_to_update_3, 'lr': 1e-3}\n",
        "], momentum=0.9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Xjh2koF4P_Y"
      },
      "source": [
        "# 学習・検証を実施"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhAJScXY4P_Y"
      },
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # 初期設定\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print()\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定であれば、高速化させる\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの訓練と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "                # GPUが使えるならGPUにデータを送る\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # 結果の計算\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKe3hnHa7BEo"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcYMkB6-4P_Z"
      },
      "source": [
        "# 学習・検証を実行する\n",
        "num_epochs=2\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X4fYysX7iFP"
      },
      "source": [
        "2021/03/14\n",
        "13時12分\n",
        "\n",
        "この本のコードは、小ラボラトリーのcudaを使って実行可能なことを確認した。\n",
        "なので次は実際にfine tuningの中身を確認する!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjVxzSIL7g6t"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTUSvlDa4P_Z"
      },
      "source": [
        "# 学習したネットワークを保存・ロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLPr2ei14P_Z"
      },
      "source": [
        "# PyTorchのネットワークパラメータの保存\n",
        "save_path = './weights_fine_tuning.pth'\n",
        "torch.save(net.state_dict(), save_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kMCPU9D4P_Z"
      },
      "source": [
        "# PyTorchのネットワークパラメータのロード\n",
        "load_path = './weights_fine_tuning.pth'\n",
        "load_weights = torch.load(load_path)\n",
        "net.load_state_dict(load_weights)\n",
        "\n",
        "# GPU上で保存された重みをCPU上でロードする場合\n",
        "load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n",
        "net.load_state_dict(load_weights)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90sgpG4ly2YT"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdqBAM7Q4P_Z"
      },
      "source": [
        "以上"
      ]
    }
  ]
}